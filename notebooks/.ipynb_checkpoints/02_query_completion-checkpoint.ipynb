{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6db38293-e1ff-4d24-85d8-7699dce71b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from scipy import spatial\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f53229-4811-4b2c-919e-30d332100cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/lizette/Documents/udacity_LLMs/project/books_data_embeddings/books_data_embeddings_0_1000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb9fde78-d77b-43da-979d-7d5a771f67f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key from .env file\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key = OPENAI_API_KEY)\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OpenAI API key not found! Make sure it's in the .env file.\")\n",
    "\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b4aa79a-1749-42a9-980e-1fd6e2fd7e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-B0Ez29Y97VFCpYqGU5sojbeQeYZcj', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='A wonderful book that fits your criteria is \"My Brilliant Friend\" by Elena Ferrante. It is the first book in Ferrante\\'s \"Neapolitan Novels\" series. The story is set in Naples and revolves around the childhood and adolescence of two girls, Elena Greco and Raffaella \"Lila\" Cerullo, as they navigate the complexities of friendship, family, and the socio-political landscape of Italy in the 1950s and beyond.\\n\\nThe book beautifully captures the nuances of their friendship, the challenges they face, and the way their lives intertwine over the years. The vivid depiction of Naples and its culture adds depth to the narrative, making it a rich and engaging read.\\n\\nIf you\\'re looking for a compelling and insightful', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1739397296, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_bd83329f63', usage=CompletionUsage(completion_tokens=150, prompt_tokens=36, total_tokens=186, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic example\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"I would like to read a book about two friends who live in napoli and grow up together\"},\n",
    "  ],\n",
    "  max_tokens = 150\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d554a05-2979-4032-8216-deeeb9d54cfc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## From openai cookbook\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# search function from udacity course\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstrings_ranked_by_relatedness\u001b[39m(\n\u001b[1;32m      5\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m----> 6\u001b[0m     df: \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame,\n\u001b[1;32m      7\u001b[0m     relatedness_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x, y: \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m spatial\u001b[38;5;241m.\u001b[39mdistance\u001b[38;5;241m.\u001b[39mcosine(x, y),\n\u001b[1;32m      8\u001b[0m     top_n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      9\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     query_embedding_response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     12\u001b[0m         model\u001b[38;5;241m=\u001b[39mEMBEDDING_MODEL,\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mquery,\n\u001b[1;32m     14\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "## From openai cookbook\n",
    "\n",
    "# search function from udacity course\n",
    "def strings_ranked_by_relatedness(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n",
    "    top_n: int = 100\n",
    ") -> tuple[list[str], list[str], list[float]]:\n",
    "    \"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\n",
    "    query_embedding_response = client.embeddings.create(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        input=query,\n",
    "    )\n",
    "    query_embedding = query_embedding_response.data[0].embedding\n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"Title\"], row[\"description\"], relatedness_fn(query_embedding, eval(row[\"embedding\"])))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[2], reverse=True)\n",
    "    titles, strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "    return titles[:top_n], strings[:top_n], relatednesses[:top_n]\n",
    "\n",
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "   \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "   encoding = tiktoken.encoding_for_model(model)\n",
    "   return len(encoding.encode(text))\n",
    "\n",
    "\n",
    "def query_message(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    model: str,\n",
    "    token_budget: int\n",
    ") -> str:\n",
    "    \"\"\"Return a message for GPT, with relevant source texts pulled from a dataframe.\"\"\"\n",
    "    titles, strings, relatednesses = strings_ranked_by_relatedness(query, df, top_n = 5)\n",
    "    introduction = 'Use the below articles to answer the subsequent question. If the answer cannot be found in the articles, write \"I could not find an answer.\"'\n",
    "    question = f\"\\n\\nQuestion: {query}\"\n",
    "    message = introduction\n",
    "    for title, string in zip(titles,strings):\n",
    "        next_article = f'\\n\\nBook title: {title}, Book description:\\n\"\"\"\\n{string}\\n\"\"\"'\n",
    "        if (\n",
    "            num_tokens(message + next_article + question, model=model)\n",
    "            > token_budget\n",
    "        ):\n",
    "            break\n",
    "        else:\n",
    "            message += next_article\n",
    "    return message + question\n",
    "\n",
    "\n",
    "def ask(\n",
    "    query: str,\n",
    "    df: pd.DataFrame = df,\n",
    "    model: str = GPT_MODEL,\n",
    "    token_budget: int = 4096 - 500,\n",
    "    print_message: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"Answers a query using GPT and a dataframe of relevant texts and embeddings.\"\"\"\n",
    "    print(\"Token budget:\", token_budget)\n",
    "    message = query_message(query, df, model=model, token_budget=token_budget)\n",
    "    if print_message:\n",
    "        print(message)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    print(response)\n",
    "    response_message = response.choices[0].message.content\n",
    "    return response_message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf3a2dcd-f57b-4991-b16c-faef321c5429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token budget: 3596\n",
      "ChatCompletion(id='chatcmpl-B0F28PDixVFiv4EZzokzBOmN9jHGy', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I could not find an answer in the provided articles.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1739397488, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=12, prompt_tokens=1124, total_tokens=1136, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I could not find an answer in the provided articles.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"I would like to read a book about two friends who live in napoli and grow up together\", df = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "560cf845-422d-4bc5-b68d-1341002d9225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token budget: 3596\n",
      "ChatCompletion(id='chatcmpl-B0F3K6EZpukkqgeGtwgb4JM1VGy5S', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='You can consider reading \"Herland\" by Charlotte Perkins Gillman. It is a feminist novel that explores ideas about gender, motherhood, community, and sexuality in a science-fiction story.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1739397562, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=39, prompt_tokens=680, total_tokens=719, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You can consider reading \"Herland\" by Charlotte Perkins Gillman. It is a feminist novel that explores ideas about gender, motherhood, community, and sexuality in a science-fiction story.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"I would like to read a feminist novel\", df = df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (book-reviews-llm venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
